{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) 2024, Mukesh Dalal. \n",
    "<mukesh@aidaa.ai>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'mc_wrap' from 'modelcaller.modelcaller' (c:\\Users\\user\\My Drive\\techbiz\\dev\\modelcaller\\modelcaller\\modelcaller.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodelcaller\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCaller, MCconfig, decorate_mc, wrap_mc\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      8\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\My Drive\\techbiz\\dev\\modelcaller\\modelcaller\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelcaller\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCaller, MCconfig, CallbackBase, FloatCallback, ArrayCallback, mc_wrap, mc_wrapd\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'mc_wrap' from 'modelcaller.modelcaller' (c:\\Users\\user\\My Drive\\techbiz\\dev\\modelcaller\\modelcaller\\modelcaller.py)"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from modelcaller import ModelCaller, MCconfig, decorate_mc, wrap_mc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "random.seed(42)\n",
    "\n",
    "def generate_data(f, count=1000, scale=100):\n",
    "    global globalx\n",
    "    inputs = np.zeros((count, 3))\n",
    "    outputs = np.zeros(count)\n",
    "    for i in range(count):\n",
    "        globalx = random.random() * scale\n",
    "        x0 = random.random() * scale\n",
    "        x1 = random.random() * scale\n",
    "        inputs[i] = [x0, x1, globalx]\n",
    "        outputs[i] = f(x0, x1)\n",
    "    return inputs, outputs\n",
    "\n",
    "def repeat_function(f, arity=2, count=10, scale=100):\n",
    "    global globalx\n",
    "    for _ in range(count):\n",
    "        globalx = random.random() * scale\n",
    "        args = [random.random() * scale for _ in range(arity)]\n",
    "        f(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@decorate_mc(cparams=['globalx'])\n",
    "def f(x0, x1): \n",
    "    global globalx\n",
    "    return 3 * x0 + x1 + globalx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = f._mc\n",
    "print('A new wrapped MC with one context argument:', mc.fullstr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_function(f)\n",
    "print('After a few function calls:', mc.fullstr(full=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "mc.add_model(LinearRegression())\n",
    "print('After training and evaluating the added model: ', mc.fullstr(full=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_function(f)\n",
    "print('After a few more function calls: ', mc.fullstr(full=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mc.get_call_target() == 'both': \n",
    "    mc.merge_host()\n",
    "    print('After merging host function: ', mc.fullstr(full=False))\n",
    "    repeat_function(f)\n",
    "    print('After a few more function calls: ', mc.fullstr(full=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "midx = mc.add_model(MLPRegressor(hidden_layer_sizes=(), activation='identity'))\n",
    "print('After training and evaluating the added model: ', mc.fullstr(full=False))\n",
    "repeat_function(f)\n",
    "print('After a few more function calls: ', mc.fullstr(full=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mc.get_call_target() == 'MC':\n",
    "    xy = generate_data(mc.get_host())\n",
    "    mc.add_dataset(xy[0], xy[1])\n",
    "    print('After adding more data but before training: ', mc.fullstr(full=False))\n",
    "    mc.train_all()\n",
    "    print('After training and evaluating with the new data: ', mc.fullstr(full=False))\n",
    "    repeat_function(f)\n",
    "    print('After a few more function calls: ', mc.fullstr(full=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mc.isqualified(midx) == False:\n",
    "    mc.qlty_threshold = -100\n",
    "    print('After updating qlty_threshold: ', mc.fullstr())\n",
    "    mc.eval_all()\n",
    "    print('After reevaluating all models with the new threshold: ', mc.fullstr(full=False))\n",
    "    repeat_function(f)\n",
    "    print('After a few more function calls: ', mc.fullstr(full=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.remove_model(1)\n",
    "mc.qlty_threshold = 0.95\n",
    "print('After removing the second model and reverting the threshold: ', mc.fullstr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidx = mc.add_function(lambda x: x * x)\n",
    "print('After adding a new function: ', mc.fullstr(full=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.remove_function(fidx)\n",
    "print('After removing the last function: ', mc.fullstr(full=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.clear_dataset()\n",
    "print('After removing all training data: ', mc.fullstr(full=False))\n",
    "repeat_function(f)\n",
    "print('After a few more function calls: ', mc.fullstr(full=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@mc.wrap_sensor()\n",
    "def fcopy(x0, x1, x3):  # y\n",
    "    return 3 * x0 + x1 + x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_function(fcopy, arity=3)\n",
    "print('After a few direct-sensor calls: ', mc.fullstr(full=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@mc.wrap_sensor('inverse')\n",
    "def finv(y, x1, x2):  # x1\n",
    "    return (y - x1 -  x2) / 3\n",
    "\n",
    "repeat_function(finv, arity=3)\n",
    "print('After a few inverse-sensor calls: ', mc.fullstr(full=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalx = 1\n",
    "y = f(2, 3)\n",
    "y.callback(100.0)\n",
    "for kind in ('tdata', 'edata'):\n",
    "    idx, out = mc.find_data([2, 3, 1], kind)\n",
    "    if idx >= 0:\n",
    "        print(f\"Feedback callback: {y:.1f} updated to {out} in _{kind}['outputs'][{idx}] for inputs [2, 3, 1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_function(mc, arity=3)\n",
    "print('After a few MC calls: ', mc.fullstr(full=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalx = 1\n",
    "y = f(2, 3)\n",
    "mc.clear_dataset('tdata')\n",
    "mc.clear_dataset('edata')\n",
    "y.callback(100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc1 = ModelCaller(MCconfig(_ncparams=1))\n",
    "print('A new unwrapped MC with one context argument: ', mc1.fullstr())\n",
    "mc1.add_model(mc.get_model(0), qualified=True) # reuse model\n",
    "repeat_function(mc1, arity=3)\n",
    "print('After a few mc calls: ', mc1.fullstr(full=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "mc1.add_model(nn.Linear(3,1), qualified=True)\n",
    "print('After adding a pytorch model: ', mc1.fullstr(full=False))\n",
    "repeat_function(mc1, arity=3)\n",
    "print('After a few mc calls: ', mc1.fullstr(full=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@decorate_mc(auto_id=None)\n",
    "def f2(x0, x1):  # y\n",
    "    return 3 * x0 + x1\n",
    "f2(10,11)\n",
    "print('A new wrapped MC with only auto-id and no other context argument, after a function call: ', f2._mc.fullstr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LinearRegression()\n",
    "m.fit([[1, 2, 3], [3, 4, 5]], [9, 10])\n",
    "fpredict = wrap_mc(m.predict)  # wrapping a predefined function\n",
    "fpredict([[10, 20, 30]])\n",
    "print('A new MC, after wrapping a model.predict and calling MC: ', fpredict._mc.fullstr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = LinearRegression()\n",
    "m = wrap_mc(m, kind='model', auto_id=True)\n",
    "mc2 = m._mc\n",
    "mc2.merge_host()\n",
    "mc2.train_all((np.array([[1, 2, 3], [3, 4, 5]], dtype=float), np.array([9, 10], dtype=float)))\n",
    "m(10, 20, 30)\n",
    "print('A new MC, after wrapping a model and calling fit and predict: ', mc2.fullstr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "API_URL = \"https://api-inference.huggingface.co/models/gpt2\"\n",
    "headers = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
    "\n",
    "@decorate_mc()\n",
    "def llm(prompt):\n",
    "    response = requests.post(API_URL, headers=headers, json=prompt)\n",
    "    return response.json()[0]['generated_text']\n",
    "\n",
    "llm(\"I want to\")\n",
    "llm(\"I do not want to\")\n",
    "print('A new MC, after two calls to GPT2:', llm._mc.fullstr())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
